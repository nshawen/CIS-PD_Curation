{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "import pickle\n",
    "from scipy.stats import skew, kurtosis, pearsonr\n",
    "from scipy.signal import butter, welch, filtfilt, resample\n",
    "import copy\n",
    "import time\n",
    "import datetime\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "from PreprocessFcns import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save corrected version of motor scores.xls \n",
    "# use updated 508/9 form instead\n",
    "mot_scores = pd.read_excel('X:CIS-PD Study\\\\Scores\\\\reformatted_form509.xls')\n",
    "# update score formatting\n",
    "# fix error in original cols labels\n",
    "mot_scores.columns.values[75] = 'alternating left hand movements tremor right upper limb'\n",
    "mot_scores.columns.values[150] = 'sitting tremor right upper limb'\n",
    "# remove words:(Qxx) and 'rating' from each column for readability\n",
    "cols= mot_scores.columns\n",
    "cols = cols.tolist()\n",
    "colsnew = [x.split('(')[0] for x in cols]\n",
    "colsnew = [x.strip() for x in colsnew] # remove whitespace\n",
    "colsnew = [x.split('rating')[0] for x in colsnew]\n",
    "colsnew = [x.strip() for x in colsnew]\n",
    "colsnew = [x.lower() for x in colsnew] # make all lower case \n",
    "colsnew = [x.replace('\\x97',' ') for x in colsnew]\n",
    "colsnew = [x.replace('â€”',' ') for x in colsnew]    \n",
    "# simplify notation\n",
    "for i in range(len(colsnew)):\n",
    "    x = colsnew[i]\n",
    "    if x.find('finger to nose')>-1:\n",
    "        colsnew[i] = x.replace(' hand','')\n",
    "    if x.find('alternating')>-1:\n",
    "        colsnew[i] = x.replace(' hand movements','')\n",
    "c = dict(zip(cols,colsnew))\n",
    "mot_scores = mot_scores.rename(index=str, columns=c)\n",
    "# change 1 month label to 4 wks for proper sorting (to incorporate in xls file)\n",
    "mot_scores.loc[mot_scores['visit']=='1 Month','visit']='4 Weeks'\n",
    "# mot_scores.to_excel('Z:CIS-PD Study\\Scores\\MotorTasks.xls') #note that timestamps are not properly converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_visit_list = pd.read_csv(\"X:\\\\CIS-PD Study\\\\subject visit list.csv\")\n",
    "subj_visit_list['FormDate'] = pd.to_datetime(subj_visit_list['FormDate'])\n",
    "\n",
    "user_id_pairings = pd.read_csv(\"X:\\\\CIS-PD MUSC\\\\decoded_forms\\\\videoID.csv\")\n",
    "\n",
    "success_rates = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataAggregator(subjDict,taskList_Abb,taskScores,sessionList,freq):\n",
    "    \n",
    "    Data = pd.DataFrame()\n",
    "    \n",
    "    numSamples = pd.DataFrame()\n",
    "    \n",
    "    s = 0\n",
    "    for subj in list(subjDict.keys()):\n",
    "        \n",
    "        s += 1\n",
    "        print('Subject %d (%d of %d)'%(subj,s,len(subjDict)))\n",
    "        \n",
    "        for t in range(len(taskList_Abb)):\n",
    "            \n",
    "            task = taskList_Abb[t]\n",
    "            task_score = taskScores[t]\n",
    "            \n",
    "            for trial in range(len(sessionList)):\n",
    "                \n",
    "                visit = sessionList[trial]\n",
    "                \n",
    "                try:\n",
    "                    data = pd.read_csv('X:CIS-PD Study\\\\MJFF Curation\\\\TaskAcc\\\\' + str(subj) + '_' + str(trial) + \n",
    "                                      '_' + task + '.csv',parse_dates=['timestamp'])[['timestamp','x','y','z']]\n",
    "                \n",
    "                except:\n",
    "                    #print('No data found for %s trial %d'%(task,trial))\n",
    "                    continue\n",
    "                    \n",
    "                side = subjDict[subj]\n",
    "                \n",
    "                subj_score = mot_scores.loc[mot_scores['subject']==subj,['subject','visit',\n",
    "                                            task_score+ ' ' + 'bradykinesia ' + side + ' upper limb',\n",
    "                                            task_score+ ' ' + 'tremor ' + side + ' upper limb']]\n",
    "                subj_score = subj_score.rename(index=str,columns={subj_score.columns[2]:'Bradykinesia',subj_score.columns[3]:'Tremor'})\n",
    "                subj_score.index = range(len(subj_score))\n",
    "                    \n",
    "                data['timestamp'] = (data.timestamp.values - data.timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "                data = data.set_index('timestamp')\n",
    "                \n",
    "                data = HPfilter(data)\n",
    "                \n",
    "                clip_data = gen_clips_mc10(data,downsample=freq,basefreq=50)\n",
    "                \n",
    "                for c in range(len(clip_data['data'])):\n",
    "                    N = pd.DataFrame()\n",
    "                    N['Subject'] = subj\n",
    "                    N['Task'] = task\n",
    "                    N['Visit'] = sessionList[trial]\n",
    "                    N['Samples'] = len(clip_data['data'][c])\n",
    "                    numSamples = pd.concat([numSamples,N])\n",
    "                \n",
    "                feature_extraction_reduced(clip_data)\n",
    "                \n",
    "                if 'features' in clip_data.keys():\n",
    "                    D = clip_data['features']\n",
    "                    featcols = list(D.columns)\n",
    "                    D['Bradykinesia'] = subj_score['Bradykinesia'][trial]\n",
    "                    D['Tremor'] = subj_score['Tremor'][trial]\n",
    "                    D['Visit'] = visit\n",
    "                    D['Task'] = task\n",
    "                    D['Subject'] = subj\n",
    "                    Data = pd.concat([Data,D])\n",
    "                    \n",
    "    cols = ['Subject','Visit','Task','Bradykinesia','Tremor'] + featcols\n",
    "    Data = Data[cols]\n",
    "    \n",
    "    #if freq==50:\n",
    "        #numSamples.to_csv('Z:CIS-PD Study\\\\Watch Sample Lengths.csv')\n",
    "    \n",
    "    return Data\n",
    "    \n",
    "    #Data.to_csv('Z:CIS-PD Study\\\\Smartwatch Data 50Hz.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the 4 digit user_id from the corresponding 6 digit user_id\n",
    "def user_id_6_to_4(user_id_6):\n",
    "    for index, row in user_id_pairings.iterrows():\n",
    "        if (not np.isnan(row['Subj ID Athena'])):\n",
    "            if (int(row['Subj ID Athena'])==int(user_id_6)):\n",
    "                return int(row['SubjectCode'])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HPfilter(rawdata,cutoff=0.75,ftype='highpass'):\n",
    "#highpass (or lowpass) filter data. HP to remove gravity (offset - limb orientation) from accelerometer data from each visit (trial)\n",
    "#input: Activity dictionary, cutoff freq [Hz], task, sensor location and type of filter (highpass or lowpass).\n",
    "\n",
    "    if rawdata.empty is False: #skip if no data for current sensor\n",
    "        idx = rawdata.index\n",
    "        idx = idx-idx[0]\n",
    "        rawdata.index = idx\n",
    "        x = rawdata.values # modify to ignore other columns\n",
    "        Fs = np.mean(1/(np.diff(rawdata.index)/1000)) #sampling rate\n",
    "\n",
    "        #filter design\n",
    "        cutoff_norm = cutoff/(0.5*Fs)\n",
    "\n",
    "        b,a = butter(4,cutoff_norm,btype=ftype,analog=False)\n",
    "        #filter data\n",
    "        xfilt = filtfilt(b,a,x,axis=0)\n",
    "        rawdatafilt = pd.DataFrame(data=xfilt,index=rawdata.index,columns=rawdata.columns)\n",
    "        return rawdatafilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HomeDataAggregator(file):\n",
    "    t1 = time.time()\n",
    "    Data = pd.DataFrame()\n",
    "    print(file)\n",
    "    \n",
    "    features_list = ['RMSX','RMSY','RMSZ','rangeX','rangeY','rangeZ','meanX','meanY','meanZ','varX','varY','varZ',\n",
    "                    'skewX','skewY','skewZ','kurtX','kurtY','kurtZ','xcor_peakXY','xcorr_peakXZ','xcorr_peakYZ',\n",
    "                    'xcorr_lagXY','xcorr_lagXZ','xcorr_lagYZ','Dom_freq','Pdom_rel','PSD_mean','PSD_std','PSD_skew',\n",
    "                    'PSD_kur','jerk_mean','jerk_std','jerk_skew','jerk_kur']\n",
    "        \n",
    "    # get acc data\n",
    "    try:\n",
    "        # change if we want to use Activity Level and Tremor Score\n",
    "        data = pd.read_pickle('X:\\\\CIS-PD Study\\\\MJFF Curation\\\\combined pre-visit data\\\\' + \n",
    "                               file)[['user_id','timestamp','Gait','x','y','z']]  \n",
    "    except:\n",
    "        print('No data found for %s trial %d'%(task,trial))\n",
    "        return\n",
    "        \n",
    "    # organize data and make 5 second clips\n",
    "    data = data.sort_values(by = 'timestamp', axis = 0)\n",
    "    \n",
    "    data['timestamp2'] = [(tm - datetime.timedelta(minutes=0,\n",
    "                                                   seconds=tm.second % 5,\n",
    "                                                   microseconds=tm.microsecond)) \n",
    "                          for tm in data.timestamp]\n",
    "    \n",
    "    data['timestamp'] = (data.timestamp.values - data.timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "    data = data.set_index('timestamp')\n",
    "    data.loc[:,['x', 'y', 'z']] = HPfilter(data[['x', 'y', 'z']])\n",
    "                \n",
    "    # \"clip\" the data into 5 second chunks    \n",
    "    five_sec_intervals = data.timestamp2.unique()\n",
    "        \n",
    "    # calculate features\n",
    "    F=[]\n",
    "    num_empty = 0\n",
    "    times = []\n",
    "    for t in five_sec_intervals:\n",
    "        clip = data.loc[(data.timestamp2 == t)] # & (data.Gait == 1)] # take only walking data\n",
    "        if (clip.empty or (len(clip.timestamp2) < 200)):\n",
    "            num_empty += 1\n",
    "        else:\n",
    "            F.append(reduced_feature_extraction_from_1_clip(clip[['x', 'y', 'z']]))\n",
    "            times.append(t)\n",
    "\n",
    "    success_info = [file, len(five_sec_intervals), (len(five_sec_intervals)-num_empty)]\n",
    "    df = pd.DataFrame(data = [success_info], columns = ['file', 'num expected clips', 'num actual clips'])\n",
    "    if (os.path.isfile(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\")):\n",
    "            dfo = pd.read_csv(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\", index_col = 0)\n",
    "            df = pd.concat([dfo, df])\n",
    "    df.to_csv(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\")\n",
    "            \n",
    "    # create features dataframe\n",
    "    D = pd.DataFrame(data=F,columns=features_list,dtype='float32')    \n",
    "    featcols = list(D.columns)\n",
    "    D['Subject'] = data.loc[0, 'user_id']\n",
    "    D['timestamp'] = times #['timestamp2']\n",
    "    Data = pd.concat([Data,D])   \n",
    "    cols = ['Subject','timestamp'] + featcols\n",
    "    Data = Data[cols]\n",
    "    elapsed_time = ((time.time() - t1)/60.0).__str__()\n",
    "    print(elapsed_time + \" mins\\n\")\n",
    "    Data.to_pickle('X:\\CIS-PD Study\\Home WACC features\\\\features ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_func(t, data):\n",
    "    clip = data.loc[(data.timestamp2 == t)] # & (data.Gait == 1)] # take only walking data\n",
    "    if not((clip.empty or (len(clip.index) < 200))):\n",
    "        return list(reduced_feature_extraction_from_1_clip(clip[['x', 'y', 'z']])).append(t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HomeDataAggregatorThreading(file):\n",
    "    t1 = time.time()\n",
    "    Data = pd.DataFrame()\n",
    "    print(file)\n",
    "    \n",
    "    features_list = ['RMSX','RMSY','RMSZ','rangeX','rangeY','rangeZ','meanX','meanY','meanZ','varX','varY','varZ',\n",
    "                    'skewX','skewY','skewZ','kurtX','kurtY','kurtZ','xcor_peakXY','xcorr_peakXZ','xcorr_peakYZ',\n",
    "                    'xcorr_lagXY','xcorr_lagXZ','xcorr_lagYZ','Dom_freq','Pdom_rel','PSD_mean','PSD_std','PSD_skew',\n",
    "                    'PSD_kur','jerk_mean','jerk_std','jerk_skew','jerk_kur', 'timestamp']\n",
    "        \n",
    "    # get acc data\n",
    "    try:\n",
    "        # change if we want to use Activity Level and Tremor Score\n",
    "        data = pd.read_pickle('X:\\\\CIS-PD Study\\\\MJFF Curation\\\\combined pre-visit data\\\\' + \n",
    "                               file)[['user_id','timestamp','Gait','x','y','z']]  \n",
    "    except:\n",
    "        print('No data found for %s trial %d'%(task,trial))\n",
    "        return\n",
    "        \n",
    "    # organize data and make 5 second clips\n",
    "    data = data.sort_values(by = 'timestamp', axis = 0)\n",
    "    \n",
    "    data['timestamp2'] = [(tm - datetime.timedelta(minutes=0,\n",
    "                                                   seconds=tm.second % 5,\n",
    "                                                   microseconds=tm.microsecond)) \n",
    "                          for tm in data.timestamp]\n",
    "    \n",
    "    data['timestamp'] = (data.timestamp.values - data.timestamp.values[0]).astype('timedelta64[ms]').astype(int)\n",
    "    data = data.set_index('timestamp')\n",
    "    data.loc[:,['x', 'y', 'z']] = HPfilter(data[['x', 'y', 'z']])\n",
    "                \n",
    "    # \"clip\" the data into 5 second chunks    \n",
    "    five_sec_intervals = data.timestamp2.unique()\n",
    "        \n",
    "    # calculate features\n",
    "    \n",
    "    \n",
    "    pool = ThreadPool(4)\n",
    "    # does type of results need to change?\n",
    "    results = pool.map(lambda t : mapping_func(t, data), five_sec_intervals)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    print(results)\n",
    "    results = list(results)\n",
    "    print('\\n')\n",
    "    print (results)\n",
    "    results = list(filter(lambda r: r is not None, results))\n",
    "\n",
    "    success_info = [file, len(five_sec_intervals), len(results)]\n",
    "    df = pd.DataFrame(data = [success_info], columns = ['file', 'num expected clips', 'num actual clips'])\n",
    "    if (os.path.isfile(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\")):\n",
    "            dfo = pd.read_csv(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\", index_col = 0)\n",
    "            df = pd.concat([dfo, df])\n",
    "    df.to_csv(\"X:\\\\CIS-PD Study\\\\Home WACC features\\\\success info.csv\")\n",
    "            \n",
    "    # create features dataframe\n",
    "    D = pd.DataFrame(data=results,columns=features_list,dtype='float32')    \n",
    "    featcols = list(D.columns)\n",
    "    D['Subject'] = data.loc[0, 'user_id']\n",
    "    Data = pd.concat([Data,D])   \n",
    "    cols = ['Subject'] + featcols\n",
    "    Data = Data[cols]\n",
    "    elapsed_time = ((time.time() - t1)/60.0).__str__()\n",
    "    print(elapsed_time + \" mins\\n\")\n",
    "    Data.to_pickle('X:\\CIS-PD Study\\Home WACC features\\\\features ' + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subjDict = {1004:'right',1016:'left',1018:'left',1019:'left',1020:'right',1024:'left',1029:'left',1030:'left',1032:'left',\n",
    "#            1038:'left',1044:'right',1046:'right',1049:'left',1051:'left'}\n",
    "subjDict = {1004:'right'}\n",
    "#1047\n",
    "\n",
    "taskList = ['Standing', 'Walking', 'Walking while counting', 'Finger to nose--right hand', \n",
    "            'Finger to nose--left hand', 'Alternating right hand movements', 'Alternating left hand movements', \n",
    "            'Sit to stand', 'Drawing on a paper', 'Typing on a computer keyboard', 'Assembling nuts and bolts', \n",
    "            'Taking a glass of water and drinking', 'Organizing sheets in a folder', 'Folding towels', 'Sitting']\n",
    "\n",
    "taskScores = ['standing','walking','walking while counting','finger to nose right','finger to nose left',\n",
    "                   'alternating right','alternating left','sit to stand','drawing on a paper',\n",
    "                   'typing on a computer keyboard','assembling nuts and bolts','taking a glass of water and drinking',\n",
    "                   'organizing sheets in a folder','folding towels','sitting']\n",
    "\n",
    "taskList_Abb = ['Stndg', 'Wlkg', 'WlkgCnt', 'FtnR', 'FtnL', 'RamR', 'RamL', 'SitStand', 'Drwg', 'Typg', 'NtsBts',\n",
    "                'Drnkg', 'Sheets', 'Fldg', 'Sitng']\n",
    "\n",
    "sessionList = ['2 Weeks: Time 0', '2 Weeks: Time 30', '2 Weeks: Time 60', '2 Weeks: Time 90', '2 Weeks: Time 120', \n",
    "               '2 Weeks: Time 150', '4 Weeks']\n",
    "\n",
    "features_list = ['RMSX','RMSY','RMSZ','rangeX','rangeY','rangeZ','meanX','meanY','meanZ','varX','varY','varZ',\n",
    "                    'skewX','skewY','skewZ','kurtX','kurtY','kurtZ','xcor_peakXY','xcorr_peakXZ','xcorr_peakYZ',\n",
    "                    'xcorr_lagXY','xcorr_lagXZ','xcorr_lagYZ','Dom_freq','Pdom_rel','PSD_mean','PSD_std','PSD_skew',\n",
    "                    'PSD_kur','jerk_mean','jerk_std','jerk_skew','jerk_kur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for freq in [50,45,40,35,30,25,20,15,10,5]:\n",
    "#    print(freq)\n",
    "#    t1 = time.time()\n",
    "#    Data = DataAggregator(subjDict,taskList_Abb,taskScores,sessionList,freq)\n",
    "#    #Data.to_csv('X:\\CIS-PD Study\\Clinic WACC features\\\\Watch Data ' + str(freq) +  'Hz.csv')\n",
    "#    t2 = (time.time() - t1)/60.0\n",
    "#    print(t2.__str__() + \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "142567 2018-01-11.pkl\n",
      "14.082773649692536 mins\n",
      "142558 2017-09-21.pkl\n",
      "9.78990361293157 mins\n",
      "142579 2017-07-07.pkl\n",
      "8.254690742492675 mins\n",
      "142621 2017-08-14.pkl\n",
      "22.94182907342911 mins\n",
      "142585 2017-09-20.pkl\n",
      "20.22361896832784 mins\n",
      "142580 2018-01-10.pkl\n",
      "14.430702904860178 mins\n",
      "142603 2017-10-13.pkl\n",
      "12.601396624247233 mins\n",
      "142583 2018-01-30.pkl\n",
      "20.280219427744548 mins\n",
      "142618 2017-08-14.pkl\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-4cfd26597573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# For every acc data file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHomeDataAggregator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;31m#Data.to_pickle('X:\\CIS-PD Study\\Clinic WACC features\\\\features ' + file)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-8dcc8c19eab2>\u001b[0m in \u001b[0;36mHomeDataAggregator\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     42\u001b[0m             \u001b[0mnum_empty\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduced_feature_extraction_from_1_clip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'x'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'y'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'z'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m             \u001b[0mtimes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\github files\\CIS-PD-wa-features\\PreprocessFcns.py\u001b[0m in \u001b[0;36mreduced_feature_extraction_from_1_clip\u001b[1;34m(a_clip_of_data)\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m#Root mean square of signal on each axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[0mN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m     \u001b[0mRMS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawdata\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    673\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    674\u001b[0m     \u001b[1;31m#range on each axis\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m   1878\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1879\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1880\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1881\u001b[0m     return _methods._sum(a, axis=axis, dtype=dtype,\n\u001b[0;32m   1882\u001b[0m                          out=out, **kwargs)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[0;32m   9567\u001b[0m                                       skipna=skipna, min_count=min_count)\n\u001b[0;32m   9568\u001b[0m         return self._reduce(f, name, axis=axis, skipna=skipna,\n\u001b[1;32m-> 9569\u001b[1;33m                             numeric_only=numeric_only, min_count=min_count)\n\u001b[0m\u001b[0;32m   9570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   9571\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mset_function_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   6849\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6850\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6851\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6852\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6853\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   6838\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6839\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6840\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6842\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnansum\u001b[1;34m(values, axis, skipna, min_count)\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mis_timedelta64_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[0mdtype_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 336\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    337\u001b[0m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_maybe_null_out\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# All Files:\n",
    "#files = os.listdir(\"X:\\\\CIS-PD Study\\\\MJFF Curation\\\\combined pre-visit data\")\n",
    "\n",
    "# Luca's Files:\n",
    "# files = ['142605 2017-08-16.pkl', '142557 2017-09-21.pkl', '142559 2017-07-06.pkl', '142617 2017-07-17.pkl', '142582 2017-07-27.pkl', '142577 2017-11-30.pkl', '142604 2017-10-02.pkl', '142604 2017-07-21.pkl', '142568 2017-09-18.pkl', '142615 2017-07-21.pkl', '142570 2017-07-13.pkl', '142623 2017-10-12.pkl', '142559 2017-07-20.pkl', '142602 2017-12-12.pkl', '142592 2017-10-03.pkl', '142561 2017-07-03.pkl', '142584 2018-02-21.pkl', '142562 2017-07-07.pkl', '142622 2017-08-03.pkl', '142606 2017-10-13.pkl', '142604 2017-08-14.pkl', '142568 2018-02-28.pkl', '142583 2017-10-13.pkl', '142618 2017-07-31.pkl', '142583 2017-08-25.pkl', '142603 2017-08-07.pkl', '142615 2017-10-05.pkl', '142595 2017-10-12.pkl', '142593 2018-01-29.pkl', '142623 2017-08-17.pkl', '142601 2017-07-13.pkl', '142570 2017-08-03.pkl', '142568 2017-09-06.pkl', '142602 2017-08-03.pkl', '142618 2017-10-30.pkl', '142616 2018-02-05.pkl', '142584 2017-11-29.pkl', '142598 2017-07-24.pkl', '142608 2017-09-18.pkl']\n",
    "\n",
    "# Nick's Files:\n",
    "# files = ['142598 2017-07-10.pkl', '142617 2017-08-01.pkl', '142603 2017-07-31.pkl', '142605 2017-08-02.pkl', '142618 2018-01-30.pkl', '142592 2017-07-13.pkl', '142558 2017-06-29.pkl', '142620 2017-07-21.pkl', '142593 2017-07-20.pkl', '142617 2017-10-03.pkl', '142594 2017-08-10.pkl', '142592 2017-07-27.pkl', '142578 2018-02-19.pkl', '142621 2017-07-21.pkl', '142612 2017-09-06.pkl', '142609 2017-08-11.pkl', '142612 2017-08-15.pkl', '142619 2017-08-10.pkl', '142608 2017-09-11.pkl', '142558 2017-07-14.pkl', '142585 2017-10-04.pkl', '142595 2018-01-10.pkl', '142557 2017-06-29.pkl', '142622 2017-10-12.pkl', '142601 2017-07-26.pkl', '142575 2017-08-29.pkl', '142581 2017-07-26.pkl', '142566 2017-07-26.pkl', '142608 2017-11-09.pkl', '142602 2017-09-20.pkl', '142606 2017-12-29.pkl', '142567 2017-07-31.pkl', '142620 2017-08-10.pkl', '142622 2017-08-17.pkl', '142583 2017-08-09.pkl', '142602 2017-07-13.pkl', '142566 2017-08-09.pkl', '142580 2017-08-01.pkl']\n",
    "\n",
    "# Julianne's Files:\n",
    "# files = ['142618 2017-08-14.pkl', '142557 2017-07-13.pkl', '142585 2018-02-02.pkl', '142581 2017-08-14.pkl', '142577 2017-08-03.pkl', '142619 2018-01-22.pkl', '142584 2017-11-01.pkl', '142600 2017-07-11.pkl', '142620 2017-10-30.pkl', '142593 2017-08-03.pkl', '142621 2017-10-23.pkl', '142609 2017-09-01.pkl', '142578 2017-09-05.pkl', '142616 2017-07-19.pkl', '142593 2017-11-06.pkl', '142600 2017-07-25.pkl', '142606 2017-08-16.pkl', '142616 2017-08-01.pkl', '142615 2017-07-07.pkl', '142595 2017-08-22.pkl', '142615 2018-01-22.pkl', '142598 2017-09-13.pkl', '142557 2017-12-11.pkl', '142601 2017-09-20.pkl', '142582 2017-08-09.pkl', '142594 2017-07-19.pkl', '142577 2017-10-11.pkl', '142579 2017-07-18.pkl', '142619 2017-07-21.pkl', '142578 2017-09-18.pkl', '142605 2017-10-11.pkl', '142575 2017-08-16.pkl', '142580 2017-07-14.pkl', '142623 2017-08-03.pkl', '142563 2017-07-18.pkl', '142604 2017-11-27.pkl', '142584 2017-09-13.pkl', '142616 2017-10-03.pkl', '142560 2017-07-03.pkl']\n",
    "\n",
    "for file in files:\n",
    "    Data = HomeDataAggregator(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool = ThreadPool(2)\n",
    "#pool.map(HomeDataAggregator, files)\n",
    "#pool.close()\n",
    "#pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
