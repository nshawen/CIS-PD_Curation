{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "from multiprocessing.dummy import Pool as ThreadPool\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculated_features = r\"X:\\CIS-PD Study\\MJFF Curation\\all pre-visit calc features\"\n",
    "watch_accelerometer = r\"X:\\CIS-PD Study\\MJFF Curation\\all pre-visit ACC\"\n",
    "combined_data = r\"X:\\\\CIS-PD Study\\\\MJFF Curation\\\\combined pre-visit data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['142578 2017-09-18.csv', '142616 2018-02-05.csv', '142557 2017-06-29.csv', '142616 2017-10-03.csv', '142620 2017-10-30.csv', '142568 2017-09-18.csv', '142558 2017-07-14.csv', '142609 2017-09-01.csv', '142612 2017-09-06.csv', '142568 2018-02-28.csv', '142615 2017-10-05.csv', '142620 2017-08-10.csv', '142593 2017-11-06.csv', '142601 2017-07-13.csv', '142603 2017-10-13.csv', '142615 2017-07-21.csv', '142558 2017-09-21.csv', '142595 2017-10-12.csv', '142621 2017-10-23.csv', '142608 2017-11-09.csv', '142580 2017-08-01.csv', '142577 2017-11-30.csv', '142603 2017-08-07.csv', '142575 2017-08-29.csv', '142608 2017-09-11.csv', '142619 2017-08-10.csv', '142577 2017-10-11.csv', '142570 2017-07-13.csv', '142604 2017-10-02.csv', '142623 2017-08-03.csv', '142585 2017-09-20.csv', '142583 2017-10-13.csv', '142616 2017-08-01.csv', '142623 2017-10-12.csv', '142604 2017-08-14.csv', '142566 2017-08-09.csv', '142561 2017-07-03.csv', '142619 2017-07-21.csv', '142605 2017-10-11.csv', '142559 2017-07-20.csv', '142592 2017-07-13.csv', '142609 2017-08-11.csv', '142602 2017-07-13.csv', '142598 2017-07-10.csv', '142581 2017-07-26.csv', '142584 2017-11-01.csv', '142619 2018-01-22.csv', '142593 2018-01-29.csv', '142579 2017-07-18.csv', '142618 2017-07-31.csv', '142606 2017-12-29.csv', '142605 2017-08-02.csv', '142602 2017-09-20.csv', '142582 2017-07-27.csv', '142598 2017-09-13.csv', '142622 2017-08-17.csv', '142585 2017-10-04.csv', '142583 2017-08-25.csv', '142618 2018-01-30.csv', '142578 2017-09-05.csv', '142615 2017-07-07.csv', '142583 2018-01-30.csv', '142562 2017-07-07.csv', '142580 2017-07-14.csv', '142616 2017-07-19.csv', '142617 2017-08-01.csv', '142567 2018-01-11.csv', '142568 2017-09-06.csv', '142563 2017-07-18.csv', '142600 2017-07-11.csv', '142622 2017-10-12.csv', '142579 2017-07-07.csv', '142623 2017-08-17.csv', '142585 2018-02-02.csv', '142558 2017-06-29.csv', '142567 2017-07-31.csv', '142618 2017-10-30.csv', '142617 2017-10-03.csv', '142584 2017-09-13.csv', '142605 2017-08-16.csv', '142578 2018-02-19.csv', '142575 2017-08-16.csv', '142557 2017-12-11.csv', '142601 2017-09-20.csv', '142606 2017-10-13.csv', '142600 2017-07-25.csv', '142621 2017-08-14.csv', '142620 2017-07-21.csv', '142584 2017-11-29.csv', '142602 2017-12-12.csv', '142604 2017-11-27.csv', '142606 2017-08-16.csv', '142557 2017-09-21.csv', '142618 2017-08-14.csv', '142577 2017-08-03.csv', '142617 2017-07-17.csv', '142566 2017-07-26.csv', '142582 2017-08-09.csv', '142594 2017-08-10.csv', '142557 2017-07-13.csv', '142601 2017-07-26.csv', '142615 2018-01-22.csv', '142560 2017-07-03.csv', '142592 2017-10-03.csv', '142612 2017-08-15.csv', '142594 2017-07-19.csv', '142622 2017-08-03.csv', '142581 2017-08-14.csv', '142608 2017-09-18.csv', '142592 2017-07-27.csv', '142583 2017-08-09.csv', '142570 2017-08-03.csv', '142593 2017-08-03.csv', '142580 2018-01-10.csv', '142559 2017-07-06.csv', '142584 2018-02-21.csv', '142598 2017-07-24.csv', '142604 2017-07-21.csv', '142603 2017-07-31.csv', '142595 2017-08-22.csv', '142593 2017-07-20.csv', '142602 2017-08-03.csv', '142595 2018-01-10.csv', '142621 2017-07-21.csv']\n"
     ]
    }
   ],
   "source": [
    "files = os.listdir(calculated_features)\n",
    "files.insert(0, files.pop(files.index('142620 2017-10-30.csv')))\n",
    "files.insert(0, files.pop(files.index('142616 2017-10-03.csv')))\n",
    "files.insert(0, files.pop(files.index('142557 2017-06-29.csv')))\n",
    "files.insert(0, files.pop(files.index('142616 2018-02-05.csv')))\n",
    "files.insert(0, files.pop(files.index('142578 2017-09-18.csv')))\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_Movements_Level(file):\n",
    "    print(file)\n",
    "    cf = pd.read_csv(calculated_features + \"\\\\\" + file)\n",
    "    for index, row in cf.iterrows():\n",
    "        if (row['measurement_id'] == 11):\n",
    "            cf = cf.drop(index)\n",
    "    cf.to_csv(calculated_features + \"\\\\\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_extra_index_columns(file):\n",
    "    print(file)\n",
    "    cf = pd.read_csv(calculated_features + \"\\\\\" + file)\n",
    "    cols = list(cf.columns.values)\n",
    "    for col in cols:\n",
    "        if \"Unnamed\" in col:\n",
    "            cf = cf.drop(col, axis = 1)\n",
    "    cf.to_csv(calculated_features + \"\\\\\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_corresponding_cf_data(tm, cf):\n",
    "    tm = tm - datetime.timedelta(minutes=0,\n",
    "                             seconds=tm.second % 5,\n",
    "                             microseconds=tm.microsecond)\n",
    "    df = cf.loc[cf['timestamp'] == tm]\n",
    "    return [float(df.loc[(df.measurement_id == 13), 'value']), \n",
    "            float(df.loc[(df.measurement_id == 10), 'value']), \n",
    "            float(df.loc[(df.measurement_id == 7), 'value'])]\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_file_2(file):\n",
    "    t1 = time.time()\n",
    "    print(\"2:\")\n",
    "    print(file)\n",
    "    cf = cf = pd.read_csv(calculated_features + \"\\\\\" + file)\n",
    "    wa = pd.read_csv(watch_accelerometer + \"\\\\\" + file)\n",
    "    \n",
    "    #if os.path.isfile(combined_data + \"\\\\\" + file):\n",
    "    #    return\n",
    "    \n",
    "    wa['timestamp'] = pd.to_datetime(wa['timestamp'])\n",
    "    cf['timestamp'] = pd.to_datetime(cf['timestamp'])\n",
    "        \n",
    "    df = wa['timestamp'].apply(lambda tm: pd.Series(find_corresponding_cf_data(tm, cf), \n",
    "                                                    index = ['Gait Detection', \n",
    "                                                             'Activity Level', \n",
    "                                                             'Tremor Score']))\n",
    "    t_elapsed = ((time.time() - t1)/60.0)\n",
    "    print(t_elapsed.__str__() + \" mins\", flush = True)\n",
    "    return pd.concat([wa, df], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for file in files:\n",
    "def merge_file(file):\n",
    "    t1 = time.time()\n",
    "    print(\"1:\")\n",
    "    print(file)\n",
    "    cf = pd.read_csv(calculated_features + \"\\\\\" + file)\n",
    "    wa = pd.read_csv(watch_accelerometer + \"\\\\\" + file)\n",
    "    \n",
    "    if os.path.isfile(combined_data + \"\\\\\" + file):\n",
    "        return\n",
    "    \n",
    "    wa['timestamp'] = pd.to_datetime(wa['timestamp'])\n",
    "    #wa['Movements Level'] = np.nan\n",
    "    wa['Gait Detection'] = np.nan\n",
    "    wa['Activity Level 5 Seconds'] = np.nan\n",
    "    wa['Tremor Score'] = np.nan\n",
    "    \n",
    "    for index, row in cf.iterrows():\n",
    "        \n",
    "        #if (row['measurement_id'] == 11):\n",
    "        #    continue\n",
    "        \n",
    "        start_time = pd.Timestamp(row['timestamp'])\n",
    "        end_time = start_time\n",
    "        measurement = row['measurement_name']\n",
    "        \n",
    "        value = row['value']\n",
    "        #if(row['measurement_id'] == 11):\n",
    "        #    end_time = start_time + pd.Timedelta('00:05:00')\n",
    "        #else:\n",
    "        end_time = start_time + pd.Timedelta('00:00:05')\n",
    "        condition = ((wa.timestamp > start_time) & (wa.timestamp < end_time))\n",
    "        wa.loc[condition, measurement] = value\n",
    "\n",
    "    wa.to_csv(combined_data + \"\\\\\" + file)\n",
    "\n",
    "    t_elapsed = ((time.time() - t1)/60.0)\n",
    "    print(t_elapsed.__str__() + \" mins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['142578 2017-09-18.csv'] #, '142616 2018-02-05.csv', \n",
    "         #'142557 2017-06-29.csv', '142616 2017-10-03.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1:\n",
      "142578 2017-09-18.csv\n",
      "2:\n",
      "142578 2017-09-18.csv\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    merge_file(file)\n",
    "    df = merge_file_2(file)\n",
    "    print(df)  \n",
    "df.style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.08473824382398823\n",
      "0.0870042880649327\n",
      "[0.0, 0.08473824382398823, 0.0870042880649327]\n"
     ]
    }
   ],
   "source": [
    "#file = files[0]\n",
    "#cf = pd.read_csv(calculated_features + \"\\\\\" + file)\n",
    "#wa = pd.read_csv(watch_accelerometer + \"\\\\\" + file)\n",
    "\n",
    "#wa['timestamp'] = pd.to_datetime(wa['timestamp'])\n",
    "#cf['timestamp'] = pd.to_datetime(cf['timestamp'])\n",
    "\n",
    "#time = wa.loc[1, 'timestamp']\n",
    "#tm = datetime.fromtimestamp(time)\n",
    "#res = find_corresponding_cf_data(time, cf)\n",
    "#for item in res:\n",
    "#    print(item)\n",
    "#print (res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pool = ThreadPool(3)\n",
    "#pool.map(merge_files, files)\n",
    "#pool.close()\n",
    "#pool.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
